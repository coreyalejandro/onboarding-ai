# Agentcraft Detailed Slide Scripts

This document contains detailed voiceover scripts, screencast directions, and on‑screen cues for every slide across the five modules of the Agentcraft orientation course. Use these scripts to record your narration and to guide the screen actions in your audition video.

------------------------------------------------------------------------

## Module 1 -- Sequester Contract

### Slide 1: Too Many Sources = No Signal

**Voiceover:**

> "You're overwhelmed. Not because you're not smart enough --- but because you're treating AI learning like you're binging Netflix. Random articles. Discord servers. Five YouTube tabs. That's not learning --- that's grazing. And grazing doesn't get you paid."

**Screencast direction:**

1. Begin with a rapid montage: open tabs flying by (YouTube, Reddit, blog posts) to illustrate information overload.
2. After 3--4 seconds, freeze the screen and desaturate it to black and white.
3. Overlay bold text in the centre of the screen: **"Too Many Sources = No Signal".**
4. After a brief pause, overlay a second line beneath it: **"Pick ONE Source. Stick With It."**

**Delivery cues:**

- As the montage freezes, play a static noise SFX for half a second, then cut to silence.
- Zoom the camera slightly (105%) when the phrase "Pick ONE Source" appears.
- Fade out the overlay before transitioning to the next slide.

------------------------------------------------------------------------

### Slide 2: Single Source of Truth (SST)

**Voiceover:**

> "Before you build an agent, build your environment. Your first tool isn't a model --- it's a mindset. That starts with a **Single Source of Truth**, or SST.
>
> "An SST means choosing one stable curriculum, one project notebook, and one reference glossary. No YouTube detours. No Twitter rabbit holes. One system. Total commitment. Until mastery.
>
> "This is your **Sequester Code**. Engineers build in constrained environments. You will too."

**Screencast direction:**

1. Display a Notion or document page titled `My Single Source of Truth`.
2. Show four checklist items:
3. ✅ Official curriculum: link to Claude Agent Docs
4. ✅ Weekly Learning Journal
5. ✅ Agent Glossary (your own definitions)
6. ✅ Parking Lot: Things to revisit later
7. Highlight each item individually as the narration references choosing one curriculum, one notebook, and one glossary.

**Delivery cues:**

- Use a soft glow or underline effect to draw attention to each checklist item as you speak about it.
- Emphasise the words "Single Source of Truth" in the narration by slowing down slightly and pausing before "SST".

------------------------------------------------------------------------

### Slide 3: Building the SST‑Aligned Workspace

**Voiceover:**

> "Here's how you do it. Step one: create a note‑taking system. Notion, Google Docs, Obsidian --- it doesn't matter. Just make it frictionless.
>
> "Step two: set your SST in stone. Link to it. Keep it open during every session. Write all notes in your own words --- not copied definitions.
>
> "Step three: add a glossary and a parking lot. Capture what you don't know --- but don't chase every unknown yet. Sequester."

**Screencast direction:**

1. Create a new page in your note‑taking tool titled `AI Agent Notebook`.
2. Add four headings:
3. 📘 SST: Claude Agent Docs
4. 🧠 Glossary (My Own Definitions)
5. 📆 Weekly Learning Journal
6. ❓ Parking Lot -- Confusions to Revisit
7. Animate the typing of each heading and briefly highlight it when complete.
8. Leave the page open at the end with all four headings visible.

**Delivery cues:**

- After typing each heading, pause for half a second, then lightly pulse the heading in sync with the narration.
- Overlay a small caption near the bottom: "Only one source allowed. Close the rest."

------------------------------------------------------------------------

### Slide 4: Declare Your SST

**Voiceover:**

> "Now it's your turn. Choose your SST. Declare it. Write it down. And pledge: you'll stick with it until the end of this module. You're not grazing anymore. You're building."

**Screencast direction:**

1. Show a sticky note or callout graphic on screen with the following fields:
2. **"My SST is:"** followed by a blank line.
3. **Title:** e.g., "Anthropic Agent Design Docs"
4. **Link:** e.g., "<https://docs.anthropic.com/claude/docs/creating-an-agent>"
5. **Pledge:** "I will not consult other sources during this module unless explicitly assigned."
6. Type in the fields as the narration mentions them.
7. Pin the sticky note to the top of your note‑taking page or workspace.

**Delivery cues:**

- As you type the pledge line, a lock icon should appear next to it.
- Display a lower‑third banner: "Declare your SST in your notebook now."

------------------------------------------------------------------------

### Slide 5: One Source. One System. One Notebook

**Voiceover:**

> "Every serious agent system starts with constraint. You are not a wanderer. You are an architect.
>
> "Remember this mantra: One Source. One System. One Notebook."

**Screencast direction:**

1. Present a blank black screen or minimalist background.
2. Fade in the three lines one by one, each on its own:
3. "One Source."
4. "One System."
5. "One Notebook."
6. After all lines appear, hold the screen for a few seconds.

**Delivery cues:**

- Play a soft chime sound each time a line fades in.
- Briefly zoom the text to 102% as each line appears, then return to 100%.

------------------------------------------------------------------------

## Module 2 -- Mental Models

### Slide 1: Chatbot != Agent

**Voiceover:**

> "Let's get one thing straight: a chatbot is not an agent. A chatbot simply returns an answer to a prompt. An agent plans, reasons, remembers, and acts. It has a persistent memory, a planner that decomposes tasks, and tools to get things done.
>
> "So when you see someone ask ChatGPT to fetch documents or manage their calendar, that's not an agent. That's wishful thinking."

**Screencast direction:**

1. Split the screen into two halves.
2. On the left, display a simple chat interface returning a trivial answer to "What's the weather?"
3. On the right, display a flowchart or diagram showing an agent: user prompt → planner → tool calls → memory update → final answer.
4. Label the chat side "Chatbot" and the diagram side "Agent".

**Delivery cues:**

- Highlight the planner, memory, and tools in the agent diagram as they're mentioned in the narration.
- Use a red "X" overlay on the chat side when the narration says "That's not an agent."

------------------------------------------------------------------------

### Slide 2: Two Lenses --- Teacher--Student & Agent Anatomy

**Voiceover:**

> "We need mental models to talk about agents. Here are two of my favourites: the teacher--student metaphor and the agent anatomy.
>
> "In the teacher--student lens, the prompt is the teacher and the model is the student. The teacher provides instructions; the student produces an answer; assignments are like tool calls; grades are like evaluations.
>
> "In the agent anatomy, we treat the agent like a living system: the brain is the planner, the eyes are the inputs, the mouth is the output, the hands are the tools, the memory is... well, memory, and the skin is the guardrails."

**Screencast direction:**

1. Show a split diagram: on the left, a teacher and a student connected by a line representing prompts/answers. Label the elements as "Teacher = Prompt/Planner", "Student = Model/Executor", "Assignments = Tools", "Grades = Evaluations".
2. On the right, show a stylised human figure (Vitruvian agent) with labelled parts: brain (planner), eyes (inputs), ears (sensors), hands (tools), mouth (outputs), memory (heart), and skin (safety/guardrails).
3. As each part is mentioned in the narration, briefly highlight it.

**Delivery cues:**

- Use coloured outlines or glow effects to draw attention to each part.
- After presenting both models, fade them into the background, preparing for the next slide.

------------------------------------------------------------------------

### Slide 3: Map Functions to Parts

**Voiceover:**

> "Let's map real agent functions onto the mental models we just explored.
>
> "Planning --- that's the brain. It decides what steps to take and in what order. Memory --- the heart: it stores context, history, and facts. Inputs --- the eyes and ears: they take in user messages, files, and sensor data. Tools --- the hands: they query databases, call APIs, and execute code. Outputs --- the mouth: that's how the agent communicates results back. Guardrails --- the skin: they enforce safety and scope.
>
> "If you can describe each capability in terms of a body part, you'll never get lost when designing or debugging."

**Screencast direction:**

1. On a single diagram (reuse the agent anatomy figure), overlay labels for each function: planner → brain, memory → memory/heart, inputs → eyes/ears, tools → hands, outputs → mouth, guardrails → skin.
2. As each function is described, animate a brief glow around the corresponding part.
3. End with the entire figure highlighted to show the holistic view.

**Delivery cues:**

- Pause briefly after each mapping to allow the learner to register the relationship.
- After finishing the mapping, display a short caption: "Mental models help us stay oriented."

------------------------------------------------------------------------

### Slide 4: Describe Your Agent in Plain Language

**Voiceover:**

> "Now I'd like you to practise: describe what an agent does in three sentences. Don't use jargon. Pretend you're explaining it to a friend who's not technical.
>
> "For example: 'An agent takes my request, plans how to achieve it using different tools, remembers important information I've shared, and gives me the final answer. It asks for clarification when needed. It knows when it doesn't know.'
>
> "Three simple sentences. Write them down now."

**Screencast direction:**

1. Show a blank text box labelled "Describe your agent in 3 sentences".
2. Fill it with the example description provided in the narration.
3. Then blank it out (so the learner has to write their own), leaving the instructions on screen.

**Delivery cues:**

- Use a subtle timer bar (30 seconds) at the bottom to indicate how long the learner has to write their own description.
- Display a lower‑third caption: "Pause the video if you need more time."

------------------------------------------------------------------------

### Slide 5: Model the Mind Before the Terms

**Voiceover:**

> "Here's the most important mental shift: model the mind before the terms. Don't let jargon lead the way. First understand the planner, the memory, the tools, the guardrails. Then learn the frameworks and acronyms.
>
> "If you do it the other way around, you'll always feel lost. But if you anchor to the cognitive structure first, every new term will make sense."

**Screencast direction:**

1. Show a funnel diagram with two paths:
2. Path A: "Terms → Confusion" (depicted as a tangled mess)
3. Path B: "Mental Models → Terms → Clarity" (depicted as a clear line)
4. Emphasise the second path as the narration progresses.
5. End with a simple mantra on screen: "Mind → Model → Terms → Clarity".

**Delivery cues:**

- Use contrasting colours for the confusing path (reds/oranges) and the clear path (greens/blues).
- Fade out the confusing path by the end of the slide, leaving only the clear path and mantra.

------------------------------------------------------------------------

## Module 3 -- Pro‑grade Checklist

### Slide 1: Prompt‑and‑Pray Fails in Real Work

**Voiceover:**

> "Let's be honest: you can't build professional systems by pasting prompts and praying for a good outcome. That's not software engineering. That's gambling.
>
> "Real systems need a clear specification: what the agent can and can't do. They need tests, so you know when it breaks. They need observability: logs and traces to see what's happening. And they need guardrails for safety.
>
> "Prompt‑and‑pray fails under pressure. Structure succeeds."

**Screencast direction:**

1. Display a cartoon or metaphor showing a person tossing dice labelled "Prompts" into a wishing well.
2. Cut to a checklist with four unchecked items: Spec, Tests, Observability, Guardrails.
3. As each item is mentioned, check it off and briefly highlight it.

**Delivery cues:**

- Use a red "X" overlay on the prompt‑and‑pray scene.
- Flash a green check mark next to each checklist item when mentioned.

------------------------------------------------------------------------

### Slide 2: Professional vs Enterprise

**Voiceover:**

> "Professional‑grade systems mean your agent works, it's testable, observable, and has guardrails. Enterprise‑grade means all that plus scalability, compliance, security, and SLAs.
>
> "For this course, professional‑grade is our bar. We're not shipping to millions of users --- yet. But we will build to the same quality standards that professionals use."

**Screencast direction:**

1. Show a two‑column comparison table:
2. Column 1: "Hobby" with blanks for Spec, Tests, Observability, Guardrails.
3. Column 2: "Professional" with green checks for those four items.
4. Column 3: "Enterprise" with additional items like "Scale", "Security", "Compliance".
5. Highlight the "Professional" column as the target for this course.

**Delivery cues:**

- Use different colour shading for the three columns: grey for Hobby, blue for Professional, darker blue for Enterprise.
- At the end, zoom slightly into the Professional column to reinforce the goal.

------------------------------------------------------------------------

### Slide 3: Grade an Agent Template Against the Checklist

**Voiceover:**

> "Let's put theory into practice. Here's an example agent template. We'll grade it against our professional‑grade checklist: Spec, Tests, Observability, Guardrails.
>
> "Spec: does it define scope and constraints? Tests: does it have golden tests? Observability: are there logs and traces? Guardrails: can it decline tasks outside scope?"

**Screencast direction:**

1. Display a sample agent configuration file on the left side of the screen (YAML or JSON).
2. On the right side, show the checklist categories with red, yellow, or green indicators.
3. Scroll through the configuration file; as you find evidence of a spec, golden tests, observability hooks, or guardrails, change the indicator from red/yellow to green.
4. Summarise the result at the bottom: which items need improvement.

**Delivery cues:**

- Use coloured dots to indicate the status of each category (red = missing, yellow = partial, green = complete).
- After highlighting each category, briefly pause to allow the learner to absorb the assessment.

------------------------------------------------------------------------

### Slide 4: Upgrade Plan -- From Hobby to Professional

**Voiceover:**

> "Here's how you upgrade a hobbyist agent to professional grade: 1. Define a clear spec: what's in scope, what's out of scope, and success criteria. 2. Add golden tests and edge cases; run them on every change. 3. Instrument the agent with logging, tracing, and metrics. 4. Implement guardrails: safe‑fail behaviours and refusal patterns. 5. Document everything: how to run it, how to extend it, how to test it."

**Screencast direction:**

1. Present a five‑step checklist, one item at a time.
2. For each step, show a concrete example: e.g. show a spec document, a golden test, a logging statement, a guardrail pattern, a README file.
3. Highlight the step as you discuss it; mark it as "Upgraded" once complete.

**Delivery cues:**

- Number each step with large, bold numbers that animate into view.
- Use consistent visual style across each example (same colours, fonts).

------------------------------------------------------------------------

### Slide 5: Spec · Test · Trace · Guardrail

**Voiceover:**

> "Let's close this module with a mantra to remember the pillars of professionalism: **Spec -- Test -- Trace -- Guardrail**.
>
> "Spec: define what it does and doesn't do. Test: ensure it works consistently. Trace: make its behaviour transparent. Guardrail: keep it safe and on scope.
>
> "If you remember these four words, you'll always have a professional foundation."

**Screencast direction:**

1. Show the four words in large type across the screen: Spec, Test, Trace, Guardrail.
2. Beneath each word, add a short descriptor:
3. Spec -- Scope & constraints
4. Test -- Golden & edge cases
5. Trace -- Logs & metrics
6. Guardrail -- Safe fail
7. After all words and descriptors appear, hold for two seconds.

**Delivery cues:**

- Sequentially animate each word into place with a slight zoom.
- Use distinct colours for each word (e.g. blue, green, orange, purple) to aid memory.

------------------------------------------------------------------------

## Module 4 -- Deterministic Evals

### Slide 1: Same Input, Different Output = Chaos

**Voiceover:**

> "Imagine asking the same question twice and getting two completely different answers. How would you debug that? How would you trust it?
>
> "Agents that behave unpredictably are chaotic and impossible to rely on. Determinism means: same input, same output. Without it, you're guessing, not testing."

**Screencast direction:**

1. Show two side‑by‑side runs of a non‑deterministic agent receiving the same input ("Summarise this report") and producing different outputs.
2. Highlight the differences between the outputs.
3. Display the word **"Chaos"** in red across both outputs.

**Delivery cues:**

- Use a shaky camera or blur effect briefly when showing the two contradictory outputs.
- After the word "Chaos" appears, cut to a blank screen before the next slide.

------------------------------------------------------------------------

### Slide 2: Golden Tests, Fixtures, and Version Pinning

**Voiceover:**

> "Golden tests are fixed input/output pairs that your agent must reproduce every time. Fixtures provide the environment and data needed for those tests. Version pinning locks your model and tools to specific versions.
>
> "Together, they guarantee reproducibility. Change the prompt? Update the model? Your golden tests will catch regressions immediately."

**Screencast direction:**

1. Display a simple YAML file defining a golden test:

```yaml
- name: summarise_report
  input: "Summarise: The system processed 500 requests with a 98% success rate."
  expected_output: "The report states that 500 requests were processed with 98% success."
```

1. Show a code snippet that loads a fixture (e.g. sample data or pre‑computed embedding).
2. Show a configuration file where the model version and tool versions are pinned.

**Delivery cues:**

- Highlight the keys `input` and `expected_output` in the YAML file to emphasise deterministic expectations.
- Overlay a padlock icon next to the version numbers to symbolise pinning.

------------------------------------------------------------------------

### Slide 3: Failing Golden → Fix → Re‑run

**Voiceover:**

> "Here's what a deterministic evaluation cycle looks like: run your agent on a golden test. If it fails, investigate why. Fix the prompt, update the tool, or adjust the planner. Then run the test again. It should pass.
>
> "Every time you change anything, rerun your golden tests. If a test fails unexpectedly, you've caught a regression."

**Screencast direction:**

1. Run a golden test and show it failing (output doesn't match expected output). Highlight the failure message.
2. Open the prompt or code and make a small fix (e.g. lower temperature or adjust the planner's instructions).
3. Run the same test again; this time it passes. Display the match message.
4. Summarise with a graphic: "Fail → Investigate → Fix → Re‑run → Pass".

**Delivery cues:**

- Use a red "Fail" badge when the test fails and a green "Pass" badge after the fix.
- Pause briefly between each step of the cycle to emphasise the process.

------------------------------------------------------------------------

### Slide 4: Write Your First Golden Test Case

**Voiceover:**

> "Now it's your turn. Choose a simple function your agent performs --- summarising text, translating a phrase, fetching the weather. Define a precise input and write down the exact output you expect. Save it as your first golden test.
>
> "Do not pick something vague or open‑ended; pick something deterministic. Write it down now."

**Screencast direction:**

1. Provide a template in the notebook or code:

```yaml
- name: my_first_test
  input: "Describe the weather in New York"
  expected_output: "It is currently sunny and 75°F in New York."
```

1. Type a different input/output pair as an example.
2. Leave a blank template for the learner to fill in.

**Delivery cues:**

- Show a timer bar indicating time to write the test.
- Add a caption: "Pause if you need more time."

------------------------------------------------------------------------

### Slide 5: Trust What You Can Re‑run

**Voiceover:**

> "Agents that behave predictably are agents you can trust. If you can re‑run a test and get the same answer, you know your system is stable. If you can't, you've discovered a bug or a design flaw.
>
> "Always trust what you can re‑run."

**Screencast direction:**

1. Show a stylised loop diagram with a test at the top, an agent run, and a result at the bottom; arrows loop back to the test.
2. Emphasise that the loop remains intact (output matches expected) when things are stable.
3. Dim the diagram if unpredictability appears.

**Delivery cues:**

- Use a loop animation to represent continuous re‑runs.
- End with the phrase "Trust What You Can Re‑run" in large type.

------------------------------------------------------------------------

## Module 5 -- Design → Build → Run

### Slide 1: What Happens When You Skip Design

**Voiceover:**

> "When you skip design, you end up hacking your way forward. You build something that barely works, can't be tested, and is impossible to extend. You have no definition of success, no constraints, and no guardrails.
>
> "That's how projects fail. You waste time debugging symptoms instead of addressing the root cause: missing design."

**Screencast direction:**

1. Show a chaotic workflow diagram with arrows pointing in all directions, representing build steps taken without a plan.
2. Show a stack of sticky notes labelled "Bug 1", "Bug 2", "Missing feature" piling up.
3. Cut to a clean blueprint labelled "Agent Design" with clearly defined components.

**Delivery cues:**

- Use red warning signs on the chaotic diagram.
- Fade out the chaos and smoothly transition to the blueprint.

------------------------------------------------------------------------

### Slide 2: Three Lanes: Design, Build, Run

**Voiceover:**

> "Building agents follows three lanes: design, build, and run.
>
> "Design means defining scope, success metrics, constraints, and failure modes. Build means writing prompts, planners, memory modules, tools, and tests. Run means deploying the agent, monitoring it, and iterating based on feedback.
>
> "If you conflate these lanes, you'll be debugging in circles."

**Screencast direction:**

1. Display a three‑column diagram labelled "Design", "Build", and "Run".
2. Under each column, list the key activities:
3. Design: Spec, constraints, success metrics, failure modes
4. Build: Prompts, planners, memory, tools, tests
5. Run: Deploy, monitor, trace, iterate
6. Use arrows to show that outputs from Design feed into Build, and outputs from Build feed into Run.

**Delivery cues:**

- Highlight one column at a time as it is described.
- At the end, draw attention to the linear flow from Design → Build → Run.

------------------------------------------------------------------------

### Slide 3: Sort a Feature into D/B/R with Hand‑offs

**Voiceover:**

> "Let's sort an example feature into the right lane. Suppose you want your agent to summarise PDF reports.
>
> "Design: specify what kinds of reports and how long the summary should be. Build: implement a PDF parser tool, create a summarising prompt, and add golden tests. Run: deploy the agent, monitor summary quality, and adjust based on feedback.
>
> "Each task belongs in only one lane. Don't mix them."

**Screencast direction:**

1. Present a feature card titled "Summarise PDF Reports".
2. Drag the card to the "Design" column and list design tasks: scope, length.
3. Drag to "Build" and list build tasks: parser tool, prompt, golden test.
4. Drag to "Run" and list run tasks: deploy, monitor, adjust.
5. Summarise by showing the card's journey across lanes.

**Delivery cues:**

- Use a smooth drag‑and‑drop animation when moving the card.
- Emphasise each column's list by highlighting it when the card lands there.

------------------------------------------------------------------------

### Slide 4: Classify Six Tasks: D vs B vs R

**Voiceover:**

> "Now let's practise. I'll show you six tasks; you decide which lane each belongs to: Design, Build, or Run.
>
> "1. Choose the maximum budget for API calls per request. 2. Write a prompt to extract key points from a transcript. 3. Add monitoring of memory usage. 4. Define what topics the agent must avoid. 5. Write golden tests for translation. 6. Update the vector store index after new documents are added.
>
> "Pause the video here, classify each task, then press play to see the answers."

**Screencast direction:**

1. Display six numbered task cards on screen.
2. Leave each card floating without indicating an answer yet.
3. After a pause, animate each card into its correct column (Design/Build/Run) with a satisfying click.
4. Display the answers on screen:
5. Design: 1, 4
6. Build: 2, 5
7. Run: 3, 6

**Delivery cues:**

- Provide a five‑second countdown timer before revealing the answers.
- Once answers appear, briefly flash the correct column headers.

------------------------------------------------------------------------

### Slide 5: Design First. Build Clean. Run Observed

**Voiceover:**

> "To wrap up: Design first. Build clean. Run observed.
>
> "Design: decide what you're going to build and why. Build: implement with clarity and tests. Run: observe, measure, iterate.
>
> "Follow this pattern, and your agents will work reliably and safely."

**Screencast direction:**

1. Present three bold words across the screen: "Design", "Build", "Run".
2. Under each word, include a short descriptor:
3. Design -- Scope, constraints, success
4. Build -- Prompts, tools, tests
5. Run -- Deploy, observe, iterate
6. Finally, show an arrow looping back from Run to Design, emphasising continuous improvement.

**Delivery cues:**

- Use smooth fade‑ins for each word.
- At the end, zoom out slightly to show the whole cycle.

------------------------------------------------------------------------
